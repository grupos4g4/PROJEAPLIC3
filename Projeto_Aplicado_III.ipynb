{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhLQp5dDydpcURXFfZ1ntT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grupos4g4/PROJEAPLIC3/blob/main/Projeto_Aplicado_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulação de arquivos e diretórios\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import re\n",
        "\n",
        "# Manipulação de imagens\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Bibliotecas científicas e numéricas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch e deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms, datasets\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "# Machine learning e métricas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "\n",
        "# Barras\n",
        "from tqdm import tqdm  # Barra de progresso\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "MZS0Y2Cb3vmJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_principal = r\"/content/drive/MyDrive/4 semestre ciências de dados /projeto_aplicado3/dataset_dividido\""
      ],
      "metadata": {
        "id": "DoNFq45r4Lhu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for root, dirs, files in os.walk(dir_principal):\n",
        "    print(f'Diretório: {root}')  # Exibe o diretório atual\n",
        "    for filename in files:\n",
        "        print(f'  Encontrado arquivo: {filename}')  # Exibe cada arquivo encontrado"
      ],
      "metadata": {
        "id": "dMIfn3Ac4PKd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = r\"/content/drive/MyDrive/4 semestre ciências de dados /projeto_aplicado3/dataset_dividido\""
      ],
      "metadata": {
        "id": "dDNW9m194VLj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicionário para armazenar a contagem de imagens por fruta\n",
        "fruit_counts = defaultdict(int)\n",
        "\n",
        "# Contador para total geral de imagens\n",
        "total_images = 0\n",
        "\n",
        "image_extensions = ('.png', '.jpg', '.jpeg')\n",
        "\n",
        "# Função para normalizar o nome da fruta\n",
        "def normalize_fruit_name(name):\n",
        "    # Extrai a parte principal do nome da fruta\n",
        "    match = re.match(r'^(apple).*', name, re.IGNORECASE)\n",
        "    return match.group(1).lower() if match else name.lower()\n",
        "\n",
        "# Percorrendo todas as subpastas e arquivos\n",
        "for root, dirs, files in os.walk(dataset):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(image_extensions):  # Verifica se o arquivo é uma imagem PNG\n",
        "            # Normaliza o nome da fruta a partir da subpasta\n",
        "            fruit_name = normalize_fruit_name(os.path.basename(root))\n",
        "            # Incrementa a contagem para a fruta correspondente\n",
        "            fruit_counts[fruit_name] += 1\n",
        "            # Incrementa o contador total de imagens\n",
        "            total_images += 1\n",
        "# Exibindo os resultados\n",
        "print(\"Total de imagens por tipo de fruta:\")\n",
        "for fruit, count in fruit_counts.items():\n",
        "    print(f'Total de imagens para {fruit}: {count}')\n",
        "# Exibindo o total geral de imagens\n",
        "print(f\"\\nTotal geral de imagens: {total_images}\")"
      ],
      "metadata": {
        "id": "pMaOQ_pz4aB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fruit_df = pd.DataFrame(list(fruit_counts.items()), columns=['Fruit', 'Count'])\n",
        "# Configurando o estilo do gráfico\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Criando um gráfico de barras\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Fruit', y='Count', data=fruit_df.sort_values('Count', ascending=False))\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Distribuição de Imagens por Tipo de Fruta')\n",
        "plt.xlabel('Tipo de Fruta')\n",
        "plt.ylabel('Número de Imagens')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qvsw-T8b4egt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um DataFrame a partir do dicionário de contagens de frutas\n",
        "fruit_df = pd.DataFrame(fruit_counts.items(), columns=['Fruit', 'Count'])\n",
        "\n",
        "# Exibindo as primeiras linhas do DataFrame\n",
        "print(fruit_df.head())\n",
        "\n",
        "# Exibindo informações gerais do DataFrame\n",
        "print(fruit_df.info())\n",
        "\n",
        "# Exibindo estatísticas descritivas\n",
        "print(fruit_df.describe())"
      ],
      "metadata": {
        "id": "FVqRhnmv4hPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando um DataFrame a partir do dicionário de contagens de frutas\n",
        "fruit_df = pd.DataFrame(fruit_counts.items(), columns=['Fruit', 'Count'])\n",
        "\n",
        "# Exibindo as primeiras linhas do DataFrame\n",
        "print(fruit_df.head())\n",
        "\n",
        "# Exibindo informações gerais do DataFrame\n",
        "print(fruit_df.info())\n",
        "\n",
        "# Exibindo estatísticas descritivas\n",
        "print(fruit_df.describe())"
      ],
      "metadata": {
        "id": "WV6HFinx-Ynq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para mostrar imagens aleatórias\n",
        "def show_random_images(fruit_name, dataset, num_images=3):\n",
        "    # Caminho da pasta da fruta\n",
        "    fruit_path = os.path.join(dataset, fruit_name)\n",
        "\n",
        "    # Verifica se o diretório existe\n",
        "    if not os.path.isdir(fruit_path):\n",
        "        print(f\"Aviso: Diretório não encontrado para {fruit_name}\")\n",
        "        return\n",
        "\n",
        "    # Lista arquivos de imagem na pasta\n",
        "    images = [img for img in os.listdir(fruit_path) if img.lower().endswith(image_extensions)]\n",
        "\n",
        "    # Se não houver imagens, exibe um aviso\n",
        "    if not images:\n",
        "        print(f\"Aviso: Nenhuma imagem encontrada para {fruit_name}\")\n",
        "        return\n",
        "\n",
        "    # Seleciona aleatoriamente as imagens\n",
        "    selected_images = random.sample(images, min(num_images, len(images)))\n",
        "\n",
        "    # Plotando as imagens\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i, img_name in enumerate(selected_images):\n",
        "        img_path = os.path.join(fruit_path, img_name)\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'{fruit_name}: {img_name}')\n",
        "    plt.show()\n",
        "\n",
        "# Caminho do dataset\n",
        "dataset_path = r\"/content/drive/MyDrive/4 semestre ciências de dados /projeto_aplicado3/dataset_dividido/train\"\n",
        "\n",
        "# Mostrando amostras para algumas frutas\n",
        "for fruit in fruit_df['Fruit'].sample(n=3, random_state=42).values:  # Seleciona aleatoriamente 3 frutas\n",
        "    show_random_images(fruit, dataset_path)"
      ],
      "metadata": {
        "id": "H18YFvUA4kSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listar_subdiretorios(dir):\n",
        "    return [os.path.join(dir, nome)\n",
        "        for nome in os.listdir(dir)\n",
        "            if os.path.isdir(os.path.join(dir, nome))]\n",
        "\n",
        "data_dir = listar_subdiretorios(dir_principal)"
      ],
      "metadata": {
        "id": "4OteXTN24nD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dest_dir = r\"/content/drive/MyDrive/4 semestre ciências de dados /projeto_aplicado3/dataset_dividido\"\n",
        "train_dir, val_dir, test_dir = [os.path.join(base_dest_dir, x) for x in ['train', 'val', 'test']]\n",
        "# Função para contar imagens em um diretório\n",
        "def contar_imagens(dir):\n",
        "    return sum([len(files) for _, _, files in os.walk(dir)])\n",
        "\n",
        "# Contar e exibir as imagens em cada conjunto\n",
        "for dir_name, dir_path in zip([\"treino\", \"validação\", \"teste\"], [train_dir, val_dir, test_dir]):\n",
        "    print(f\"Número total de imagens no conjunto de {dir_name}: {contar_imagens(dir_path)}\")"
      ],
      "metadata": {
        "id": "Jg_39Nwu4ptr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar as imagens em cada conjunto\n",
        "num_train = contar_imagens(train_dir)\n",
        "num_val = contar_imagens(val_dir)\n",
        "num_test = contar_imagens(test_dir)\n",
        "\n",
        "# Número total de imagens\n",
        "total_imagens = num_train + num_val + num_test\n",
        "\n",
        "# Calcular porcentagens\n",
        "porc_train = (num_train / total_imagens) * 100\n",
        "porc_val = (num_val / total_imagens) * 100\n",
        "porc_test = (num_test / total_imagens) * 100\n",
        "\n",
        "# Exibir os resultados\n",
        "print(f\"Número total de imagens: {total_imagens}\")\n",
        "print(f\"Treino: {num_train} imagens ({porc_train:.2f}%)\")\n",
        "print(f\"Validação: {num_val} imagens ({porc_val:.2f}%)\")\n",
        "print(f\"Teste: {num_test} imagens ({porc_test:.2f}%)\")"
      ],
      "metadata": {
        "id": "T-E5bOHU4sZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir as transformações para os dados\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),  # Aumento de dados\n",
        "        transforms.ToTensor(),  # Converter para tensor\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalizar com média e desvio padrão de ImageNet\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Carregar os dados\n",
        "image_datasets = {x: datasets.ImageFolder(root=f'{base_dest_dir}/{x}', transform=data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "# DataLoaders para carregar os dados em lotes\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4)\n",
        "               for x in ['train', 'val']}\n",
        "\n",
        "# Número de classes no dataset\n",
        "num_classes = len(image_datasets['train'].classes)"
      ],
      "metadata": {
        "id": "bn0XnnOw4vCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o modelo ResNet50 com os pesos mais recentes do ImageNet\n",
        "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Congelar as camadas convolucionais\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Substituir a última camada para o número correto de classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Enviar o modelo para a GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "_8URgaPa4yfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificanso a GPU\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "IYHOemwa40z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a função de perda\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Definir o otimizador (apenas para os parâmetros da última camada)\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ldcvzO7N429M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para treinar o modelo com barra de progresso\n",
        "def train_model(model, criterion, optimizer, dataloaders, device, num_epochs=10):\n",
        "    model.train()  # Colocar o modelo em modo de treino\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")  # Exibir o número da época\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        total_samples = len(dataloaders['train'].dataset)\n",
        "\n",
        "        # Criar a barra de progresso\n",
        "        progress_bar = tqdm(dataloaders['train'], desc=\"Treinando\", unit=\"batch\")\n",
        "\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zerar os gradientes\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass e otimização\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Estatísticas\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # Atualizar barra de progresso com a loss atual\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Calcular métricas da época\n",
        "        epoch_loss = running_loss / total_samples\n",
        "        epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "        # Exibir estatísticas da época\n",
        "        print(f\" Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "# Treinar o modelo\n",
        "train_model(model, criterion, optimizer, dataloaders, device, num_epochs=10)"
      ],
      "metadata": {
        "id": "B1E8KqfP4508"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7hXx83C_MHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloaders, device):\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    running_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    accuracy = running_corrects.double() / len(dataloaders['val'].dataset)\n",
        "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Avaliar o modelo no conjunto de validação\n",
        "evaluate_model(model, dataloaders, device)"
      ],
      "metadata": {
        "id": "RnnNRT15485s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00CHWaQx_Pfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descongelar todas as camadas\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Compilar o otimizador para ajustar todas as camadas agora\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Treinar novamente o modelo com fine-tuning\n",
        "train_model(model, criterion, optimizer, dataloaders, device, num_epochs=10)"
      ],
      "metadata": {
        "id": "WykbPgcb4_DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model_with_metrics(model, dataloaders, device, class_names):\n",
        "    model.eval()  # Colocar o modelo em modo de avaliação\n",
        "    running_corrects = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    accuracy = running_corrects.double() / len(dataloaders['val'].dataset)\n",
        "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Calcular e plotar a matriz de confusão\n",
        "    plot_confusion_matrix(all_labels, all_preds, class_names)\n",
        "\n",
        "    # Relatório de classificação\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Chame a função de avaliação com métricas\n",
        "class_names = dataloaders['train'].dataset.classes  # Obtém os nomes das classes\n",
        "evaluate_model_with_metrics(model, dataloaders, device, class_names)"
      ],
      "metadata": {
        "id": "E2NGR-zF5B-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b9yQCmMH_XxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_with_f1(model, dataloaders, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')  # Ajuste a média conforme necessário\n",
        "    print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "id": "Kazz4NGS5GLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rz-Yqg73_a1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_with_precision_recall(model, dataloaders, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}')"
      ],
      "metadata": {
        "id": "ARarVSLZ5Kv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo no conjunto de validação com métricas\n",
        "evaluate_model_with_f1(model, dataloaders, device)\n",
        "evaluate_model_with_precision_recall(model, dataloaders, device)"
      ],
      "metadata": {
        "id": "Jyxb8naf5Ofa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), r\"/content/drive/MyDrive/4 semestre ciências de dados /projeto_aplicado3/modelo_pesos.pth\")"
      ],
      "metadata": {
        "id": "QLkCp2wM5RdI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}